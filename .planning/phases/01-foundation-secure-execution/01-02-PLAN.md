---
phase: 01-foundation-secure-execution
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - src/agent/core.py
  - src/agent/tools/sandbox.py
  - src/main.py
  - src/agent/prompts.py
autonomous: false
requirements: [ENG-01, SEC-01, ENG-02]
user_setup:
  - service: OpenAI / Anthropic / Gemini
    why: "LLM for the agent"
    env_vars:
      - name: OPENAI_API_KEY
        source: "OpenAI Dashboard"
      - name: ANTHROPIC_API_KEY
        source: "Anthropic Dashboard"
must_haves:
  truths:
    - "The agent uses Pydantic AI to reason about user prompts."
    - "The agent identifies the need to run code and calls the sandbox tool."
    - "Execution pauses for user approval before any code runs in the sandbox."
    - "User can see the code that is about to be executed."
  artifacts:
    - path: "src/agent/core.py"
      provides: "Pydantic AI Agent definition and run loop"
    - path: "src/agent/tools/sandbox.py"
      provides: "Sandboxed execution tool with HITL"
    - path: "src/main.py"
      provides: "CLI entry point and Bridge for HITL approvals"
  key_links:
    - from: "src/agent/core.py"
      to: "src/agent/tools/sandbox.py"
      via: "Tool registration"
    - from: "src/agent/tools/sandbox.py"
      to: "src/sandbox/languages.py"
      via: "Open Interpreter configuration"
---

<objective>
Integrate Pydantic AI with the sandboxed execution environment and implement a mandatory Human-in-the-loop (HITL) approval flow. This plan completes the core "Brain" and "Hands" of the IronClaw system, enabling safe, agentic system interaction.

Purpose: Provide a controlled, intelligent interface for system operations.
Output: A functional agent that reasons via Pydantic AI and executes code via a sandboxed, HITL-protected interpreter.
</objective>

<execution_context>
@/home/brassy/.gemini/get-shit-done/workflows/execute-plan.md
@/home/brassy/.gemini/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation-secure-execution/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Sandboxed Agent Core</name>
  <files>src/agent/core.py, src/agent/tools/sandbox.py, src/agent/prompts.py</files>
  <action>
    Define the Pydantic AI Agent and create the sandboxed tool wrapper.
    - Implement `src/agent/tools/sandbox.py`:
      - Initialize an `Open Interpreter` instance.
      - Configure it to use `DockerPython` and `DockerShell` from Plan 01-01.
      - Define a tool function (e.g., `run_system_task`) that takes a natural language task, uses Open Interpreter to generate code, and (for now) executes it to return the result.
    - Implement `src/agent/core.py`:
      - Define a `pydantic_ai.Agent`.
      - System Prompt: Instructions on how to use the `run_system_task` tool.
      - Inject dependencies (SandboxManager, etc.) via Pydantic AI's `deps`.
    - Implement `src/agent/prompts.py`: Store system prompts for better maintainability.
  </action>
  <verify>
    <automated>python3 -c "from src.agent.core import ironclaw_agent; # Add a mock call to verify tool registration"</automated>
    <manual>N/A</manual>
    <sampling_rate>once after implementation</sampling_rate>
  </verify>
  <done>Pydantic AI Agent is correctly integrated with the sandboxed Open Interpreter tool.</done>
</task>

<task type="auto">
  <name>Task 2: HITL Implementation</name>
  <files>src/agent/tools/sandbox.py</files>
  <action>
    Implement mandatory Human-in-the-loop (HITL) approval in the sandbox tool.
    - Modify the `run_system_task` tool to follow a "Staged Execution" pattern:
      1. Use Open Interpreter to *plan* the execution and generate code.
      2. Instead of calling `interpreter.run()`, return a `CodeExecutionRequest` object (or a structured string) containing the code and a request for approval.
      3. Use Pydantic AI's ability to return structured data to the caller (the Bridge).
    - Implement the second stage: A tool or mechanism to `confirm_execution` that actually runs the code once the user provides a "go-ahead" via the bridge.
    - Ensure destructive commands (rm, etc.) trigger more prominent warnings.
  </action>
  <verify>
    <automated>pytest -v (Verify that the tool returns a 'Pending' status and the code to be run)</automated>
    <manual>N/A</manual>
    <sampling_rate>once after implementation</sampling_rate>
  </verify>
  <done>HITL approval flow is enforced for all code execution requests.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 3: CLI Bridge & End-to-End Verification</name>
  <files>src/main.py</files>
  <action>
    Implement a simple CLI entry point (`src/main.py`) that uses the `ironclaw_agent` to interact with the user. It should:
    - Handle the Pydantic AI agent run loop.
    - Detect "CodeExecutionRequest" from the agent.
    - Prompt the user for approval via the CLI.
    - Pass the approval back to the agent or call the confirmation tool directly.
  </action>
  <verify>
    <automated>python3 src/main.py --version</automated>
    <manual>
    1. Run `python3 src/main.py`.
    2. Ask the agent: "Create a file named hello.txt in the workspace with the content 'IronClaw was here'".
    3. Verify that the agent responds with a plan and the code it wants to run.
    4. Verify that it asks for your approval.
    5. Type 'yes' or 'approve'.
    6. Verify that the agent executes the code and confirms the file was created.
    7. Check the host directory mapped to `/workspace` to confirm `hello.txt` exists.
    </manual>
    <sampling_rate>once after implementation</sampling_rate>
  </verify>
  <done>End-to-end flow is verified by a human user via the CLI bridge.</done>
</task>

</tasks>

<verification>
- Agent reasoning is observable.
- HITL prompt is clear and correctly stops execution.
- Approved code runs correctly in the Docker sandbox.
- Final results are reported back to the user.
</verification>

<success_criteria>
- The system correctly refuses to run code without explicit human approval.
- Approved code executes successfully and modifies the sandboxed environment as expected.
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-secure-execution/01-02-SUMMARY.md`
</output>
