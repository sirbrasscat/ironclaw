---
phase: 03-web-dashboard-security
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified: [src/agent/core.py, src/agent/tools/sandbox.py, src/web_ui.py]
autonomous: true
requirements: [WEB-02, SEC-02]

must_haves:
  truths:
    - "User can see the agent's internal thoughts and tool calls in real-time."
    - "User can see the interpreter's console output as it executes code."
  artifacts:
    - path: "src/agent/core.py"
      provides: "Streaming support via deps"
    - path: "src/agent/tools/sandbox.py"
      provides: "Output callback for confirm_execution"
    - path: "src/web_ui.py"
      provides: "Chainlit streaming implementation"
  key_links:
    - from: "src/web_ui.py"
      to: "ironclaw_agent.run_stream"
      via: "async with block"
    - from: "src/agent/tools/sandbox.py"
      to: "cl.Step"
      via: "on_output callback passed through deps"
---

<objective>
Enhance the web UI to provide real-time streaming of agent reasoning and execution logs.
Purpose: To improve transparency and user trust by showing what the agent is doing and what the results of its actions are as they happen.
Output: A more responsive UI with live feedback during both the thinking and execution phases.
</objective>

<execution_context>
@/home/brassy/.gemini/get-shit-done/workflows/execute-plan.md
@/home/brassy/.gemini/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-web-dashboard-security/03-01-SUMMARY.md
@src/web_ui.py
@src/agent/core.py
@src/agent/tools/sandbox.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Prepare Agent and Sandbox for Streaming</name>
  <files>src/agent/core.py, src/agent/tools/sandbox.py</files>
  <action>
    Modify the agent and tools to support passing an output callback via Pydantic AI dependencies:
    1. In `src/agent/core.py`:
       - Define an `AgentDeps` dataclass with an optional `on_output: Callable[[str], None]` field.
       - Update `ironclaw_agent` to use `deps_type=AgentDeps`.
       - Change `confirm_execution` tool from `tool_plain` to `tool` and have it accept `RunContext[AgentDeps]`.
       - Pass `ctx.deps.on_output` to the underlying `_confirm_execution` call.
    2. In `src/agent/tools/sandbox.py`:
       - Update `SandboxedTool.confirm_execution` and the module-level `confirm_execution` function to accept an optional `on_output` callback.
       - Inside the loop that consumes `interpreter.computer.run` chunks, call `on_output(content)` for every console chunk.
  </action>
  <verify>
    <automated>pytest tests/test_interpreter_behavior.py</automated>
    <manual>Verify code compiles and `confirm_execution` signature now accepts the new parameter.</manual>
    <sampling_rate>run after this task commits</sampling_rate>
  </verify>
  <done>Agent and tools are ready to pipe live output from the sandbox to a caller-provided callback.</done>
</task>

<task type="auto">
  <name>Task 2: Implement Real-time Streaming in Chainlit</name>
  <files>src/web_ui.py</files>
  <action>
    Refactor `on_message` in `src/web_ui.py` to use Pydantic AI's streaming capabilities and handle live execution logs:
    1. Replace `ironclaw_agent.run` with `async with ironclaw_agent.run_stream(...) as stream:`.
    2. Create a `cl.Step` to show the agent's progress. Use `stream.get_data()` or `stream.stream_text()` to show content as it arrives.
    3. In the `run_stream` call, pass an `AgentDeps` object.
    4. Define a callback inside `on_message` that sends tokens to the active Chainlit message or a dedicated `cl.Step` for execution logs.
    5. Ensure `CodeExecutionRequest` still triggers the existing `handle_code_approval` flow when it's the final result.
    6. Update `handle_code_approval` to use the streaming-enabled `ironclaw_agent.run` (the second call that triggers `confirm_execution`).
  </action>
  <verify>
    <automated>python src/web_ui.py --help</automated>
    <manual>Launch `chainlit run src/web_ui.py`. Ask the agent to run a command like `for i in {1..3}; do echo "Step $i"; sleep 1; done`. Verify that "Step 1", "Step 2", etc., appear live after approval.</manual>
    <sampling_rate>run after this task commits</sampling_rate>
  </verify>
  <done>UI shows live streaming for both agent thoughts/tool-calls and sandbox execution output.</done>
</task>

</tasks>

<verification>
- Start the web dashboard and log in.
- Execute a task that involves code (e.g., "Check disk space").
- Verify that the agent's "thinking" process is visible.
- Approve the code execution.
- Verify that the execution logs appear in the UI as the code runs, not just at the end.
</verification>

<success_criteria>
1. Agent reasoning and tool calls are streamed to the UI.
2. Sandbox console output is streamed to the UI during execution.
3. HITL approval flow remains functional.
4. Conversation history persists correctly after streaming finishes.
</success_criteria>

<output>
After completion, create `.planning/phases/03-web-dashboard-security/03-02-SUMMARY.md`
</output>
