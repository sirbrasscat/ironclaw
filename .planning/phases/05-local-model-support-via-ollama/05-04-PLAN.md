---
phase: 05-local-model-support-via-ollama
plan: 04
type: execute
wave: 1
depends_on: []
files_modified:
  - src/agent/core.py
  - src/agent/tools/sandbox.py
  - .planning/REQUIREMENTS.md
autonomous: true
requirements: [ENG-05]
gap_closure: true

must_haves:
  truths:
    - "Ollama code generation streams tokens through the on_output callback progressively"
    - "ENG-05 traceability table in REQUIREMENTS.md is complete and accurate"
  artifacts:
    - path: "src/agent/tools/sandbox.py"
      provides: "Module-level run_system_task wrapper accepts and forwards on_output"
      contains: "def run_system_task(task: str, on_output"
    - path: "src/agent/core.py"
      provides: "run_system_task tool registration uses RunContext to access deps.on_output"
      contains: "@ironclaw_agent.tool"
    - path: ".planning/REQUIREMENTS.md"
      provides: "ENG-05 row lists 05-01, 05-02, 05-03 with status Complete"
      contains: "05-01, 05-02, 05-03 | Complete"
  key_links:
    - from: "src/agent/core.py"
      to: "src/agent/tools/sandbox.py"
      via: "run_system_task(task, on_output=on_output) where on_output comes from ctx.deps"
      pattern: "on_output.*ctx\\.deps"
---

<objective>
Close two gaps from the Phase 05 verification report: wire the on_output streaming callback from the Pydantic AI agent layer into the Ollama code-generation step, and update the stale ENG-05 traceability row in REQUIREMENTS.md.

Purpose: Ollama users currently see a batch wait during code generation â€” tokens accumulate silently instead of streaming progressively. The root cause is that the tool registration uses @ironclaw_agent.tool_plain (no RunContext), so deps.on_output is never read. Switching to @ironclaw_agent.tool and threading the callback through closes the gap.
Output: on_output callback reaches SandboxedTool.run_system_task() during agent calls; REQUIREMENTS.md traceability row is accurate.
</objective>

<execution_context>
@/home/brassy/.claude/get-shit-done/workflows/execute-plan.md
@/home/brassy/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

<interfaces>
From src/agent/core.py (current state relevant to the fix):

```python
@dataclass
class AgentDeps:
    on_output: Optional[Callable[[str], None]] = None

ironclaw_agent = Agent(
    default_model,
    system_prompt=IRONCLAW_SYSTEM_PROMPT,
    deps_type=AgentDeps,
    output_type=Union[CodeExecutionRequest, str]
)

# CURRENT (broken) -- tool_plain has no RunContext, on_output is never passed:
@ironclaw_agent.tool_plain
def run_system_task(task: str) -> Union[CodeExecutionRequest, str]:
    return _run_system_task(task)

# EXISTING working pattern to match -- confirm_execution already uses @tool with RunContext:
@ironclaw_agent.tool
def confirm_execution(ctx: RunContext[AgentDeps]) -> str:
    on_output = ctx.deps.on_output if ctx.deps else None
    return _confirm_execution(on_output=on_output)
```

From src/agent/tools/sandbox.py (current module-level wrapper, line 179):

```python
# CURRENT (broken) -- drops on_output entirely:
def run_system_task(task: str) -> Union[CodeExecutionRequest, str]:
    """Plan a system task and request approval for code execution."""
    return get_sandbox_tool().run_system_task(task)
```

From src/agent/tools/sandbox.py (SandboxedTool.run_system_task already accepts on_output):

```python
def run_system_task(
    self,
    task: str,
    on_output: Optional[Callable[[str], None]] = None,
) -> Union[CodeExecutionRequest, str]:
```

Imports already at top of sandbox.py: Optional, Callable are imported from typing -- no new imports needed.

From .planning/REQUIREMENTS.md (stale row, line 51):
  | ENG-05 | Phase 5 | 05-01, 05-02 | In Progress |
Target row:
  | ENG-05 | Phase 5 | 05-01, 05-02, 05-03 | Complete |
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire on_output callback from agent layer into run_system_task</name>
  <files>src/agent/core.py, src/agent/tools/sandbox.py</files>
  <action>
Two targeted edits. Do not touch any other logic.

Edit 1 -- src/agent/core.py:
Replace the run_system_task tool registration (lines 50-56). Change @ironclaw_agent.tool_plain to @ironclaw_agent.tool, add ctx: RunContext[AgentDeps] as first parameter, and thread on_output through to the wrapper call.

Replace with:

    @ironclaw_agent.tool
    def run_system_task(ctx: RunContext[AgentDeps], task: str) -> Union[CodeExecutionRequest, str]:
        """
        Plans a natural language task in the sandboxed environment and generates code.
        Use this for any system operations. It will return a request for approval.
        """
        on_output = ctx.deps.on_output if ctx.deps else None
        return _run_system_task(task, on_output=on_output)

Edit 2 -- src/agent/tools/sandbox.py:
Update the module-level run_system_task wrapper (line 179) to accept and forward on_output:

    def run_system_task(task: str, on_output: Optional[Callable[[str], None]] = None) -> Union[CodeExecutionRequest, str]:
        """Plan a system task and request approval for code execution."""
        return get_sandbox_tool().run_system_task(task, on_output=on_output)

No new imports are needed in either file. Do NOT change the Gemini branch or any other function.
  </action>
  <verify>
    <automated>cd /home/brassy/github/ironclaw && /home/brassy/github/ironclaw/venv/bin/python -c "import inspect; from src.agent.tools.sandbox import run_system_task; sig = inspect.signature(run_system_task); assert 'on_output' in sig.parameters, f'on_output missing: {sig}'; print('sandbox wrapper OK:', sig)"</automated>
  </verify>
  <done>run_system_task module-level wrapper signature includes on_output parameter; @ironclaw_agent.tool (not tool_plain) is used in core.py so RunContext is received; on_output flows from agent deps through to SandboxedTool.run_system_task()</done>
</task>

<task type="auto">
  <name>Task 2: Update ENG-05 traceability row in REQUIREMENTS.md</name>
  <files>.planning/REQUIREMENTS.md</files>
  <action>
In .planning/REQUIREMENTS.md, find the traceability table row for ENG-05 (currently line 51):

  | ENG-05 | Phase 5 | 05-01, 05-02 | In Progress |

Replace it with:

  | ENG-05 | Phase 5 | 05-01, 05-02, 05-03 | Complete |

Also update the "Last updated" footer line at the bottom of the file to today's date: 2026-02-28.

No other changes.
  </action>
  <verify>
    <automated>grep "ENG-05" /home/brassy/github/ironclaw/.planning/REQUIREMENTS.md</automated>
  </verify>
  <done>ENG-05 row reads "05-01, 05-02, 05-03 | Complete"; last updated date is 2026-02-28</done>
</task>

</tasks>

<verification>
After both tasks:
1. Python import check: run_system_task wrapper has on_output in its signature
2. REQUIREMENTS.md grep confirms ENG-05 row shows 05-01, 05-02, 05-03 | Complete
3. Run existing tests to confirm no regressions: cd /home/brassy/github/ironclaw && /home/brassy/github/ironclaw/venv/bin/pytest tests/ -x -q 2>&1 | tail -20
</verification>

<success_criteria>
- on_output callback is threaded from AgentDeps through RunContext into the module-level run_system_task wrapper and on to SandboxedTool.run_system_task() -- Ollama tokens will now forward to any caller-provided callback during code generation
- REQUIREMENTS.md traceability row for ENG-05 is accurate: lists all three plans and shows Complete status
- All existing tests pass (no regressions from the @tool_plain -> @tool change)
</success_criteria>

<output>
After completion, create `.planning/phases/05-local-model-support-via-ollama/05-04-SUMMARY.md`
</output>
