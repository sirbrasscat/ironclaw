---
phase: 06-phase4-workspace-verification
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - .planning/phases/04-workspace-file-management/04-UAT.md
  - .planning/phases/04-workspace-file-management/04-VERIFICATION.md
autonomous: false
requirements:
  - ENG-03
  - WEB-03
must_haves:
  truths:
    - "All 5 UAT tests in 04-UAT.md have recorded results (no [pending] entries remain)"
    - "04-UAT.md summary block reflects actual pass/fail/pending counts"
    - "04-VERIFICATION.md exists at .planning/phases/04-workspace-file-management/04-VERIFICATION.md"
    - "VERIFICATION.md formally signs off on ENG-03 and WEB-03 with UAT test numbers as evidence"
  artifacts:
    - path: ".planning/phases/04-workspace-file-management/04-UAT.md"
      provides: "UAT results for all 5 tests"
      contains: "result: [pass] or result: [fail:..."
    - path: ".planning/phases/04-workspace-file-management/04-VERIFICATION.md"
      provides: "Formal verification sign-off for Phase 4"
      contains: "ENG-03"
  key_links:
    - from: ".planning/phases/04-workspace-file-management/04-UAT.md"
      to: ".planning/phases/04-workspace-file-management/04-VERIFICATION.md"
      via: "UAT test numbers cited in evidence column"
      pattern: "UAT Test [1-5]"
    - from: ".planning/phases/04-workspace-file-management/04-VERIFICATION.md"
      to: "ENG-03 and WEB-03 in requirements table"
      via: "Requirements Coverage table rows"
      pattern: "ENG-03|WEB-03"
---

<objective>
Run all 5 pending UAT tests for Phase 4 workspace file management against the live Chainlit web UI, record results in 04-UAT.md, then write 04-VERIFICATION.md to formally close ENG-03 and WEB-03.

Purpose: Phase 4 was fully implemented but never formally verified. The v1.0 audit found no VERIFICATION.md and 0/5 UAT tests recorded. This plan closes that gap and brings milestone v1.0 to 11/11 formally verified requirements.
Output: Updated 04-UAT.md with all 5 test results, new 04-VERIFICATION.md with requirement sign-off.
</objective>

<execution_context>
@/home/brassy/.claude/get-shit-done/workflows/execute-plan.md
@/home/brassy/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-workspace-file-management/04-UAT.md
@.planning/phases/04-workspace-file-management/04-01-SUMMARY.md
@.planning/phases/04-workspace-file-management/04-02-SUMMARY.md
@.planning/phases/05-local-model-support-via-ollama/05-VERIFICATION.md

<interfaces>
<!-- Key patterns the executor needs. Extracted from existing VERIFICATION.md files. -->

From .planning/phases/05-local-model-support-via-ollama/05-VERIFICATION.md (frontmatter format):
```yaml
---
phase: 04-workspace-file-management
verified: <ISO timestamp>
status: passed        # or: partial
score: X/5 UAT tests passed
---
```

From existing VERIFICATION.md files (Observable Truths table format):
```markdown
| # | Truth | Status | Evidence |
|---|-------|--------|----------|
| 1 | [behavior] | VERIFIED | UAT Test 1: [pass] |
```

From existing VERIFICATION.md files (Requirements Coverage table format):
```markdown
| Requirement | Source Plans | Description | Status | Evidence |
|-------------|-------------|-------------|--------|----------|
| ENG-03 | 04-01, 04-02 | Workspace file management for agent | SATISFIED | UAT tests 1-5 all pass |
```

UAT result field format (from 04-UAT.md):
```markdown
result: [pass]
result: [fail: description of observed behavior]
```
</interfaces>
</context>

<tasks>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 1: Execute all 5 UAT tests and record results in 04-UAT.md</name>
  <files>.planning/phases/04-workspace-file-management/04-UAT.md</files>
  <action>
    Pause for human to run the live Chainlit application and exercise each of the 5 UAT test cases
    in order. After each test the human reports the result; Claude updates the result: field in
    04-UAT.md. After all 5 tests are reported, Claude also updates the Summary block counters.

    SETUP the human must complete before any test:
    1. Build Docker image: `docker build -t ironclaw-agent .` (from repo root)
    2. Start web UI: `chainlit run src/web_ui.py`
    3. Open http://localhost:8000 and log in (default password: ironclaw)
    4. Any LLM provider is acceptable — tests are provider-agnostic

    TEST SEQUENCE (run in order — tests 2, 3, 4 depend on files from test 1):

    TEST 1 — Upload a file via the web UI:
    Expected: Attach a file via paperclip icon. File appears in ./workspace/ on disk AND
    a confirmation message appears in chat.

    TEST 2 — Agent can list workspace files:
    Expected: Ask "what files are in my workspace?" — agent calls list_workspace_files
    and responds with names of files in ./workspace/ (including file from test 1).

    TEST 3 — Uploaded files accessible inside Docker sandbox:
    Expected: Ask agent to read the uploaded file. Agent accesses it at /workspace/filename
    inside the container and returns contents.
    NOTE: If Docker daemon is stopped this test will fail as a setup issue, not a feature bug.

    TEST 4 — /files command shows workspace contents:
    Expected: Type /files in chat. UI responds with file list, each as a clickable download link.
    NOTE: If workspace is empty, ensure test 1 left a file behind or upload one before this test.

    TEST 5 — Auto-discovery of agent-created files:
    Expected: Ask agent to "create a file called output.txt with the text hello world". After
    clicking Approve on the HITL approval step, UI automatically shows a download link for
    output.txt without typing /files.
    NOTE: HITL approval buttons are required and expected — not a bug.

    AFTER ALL TESTS: Update the ## Summary block in 04-UAT.md with actual pass/fail/pending counts.
  </action>
  <verify>
    Open .planning/phases/04-workspace-file-management/04-UAT.md and confirm all 5 test
    entries show result: [pass] or result: [fail: ...] with no [pending] remaining, and
    the ## Summary block sums to 5 total.
  </verify>
  <done>All 5 UAT tests have recorded results (pass or fail) in 04-UAT.md; no test is left as [pending]; summary block counts are accurate.</done>
  <what-built>
    This task is the UAT execution itself. The human runs the live application and exercises each
    of the 5 test cases in order. Claude records the results in 04-UAT.md after the human reports.
  </what-built>
  <how-to-verify>
    1. Open .planning/phases/04-workspace-file-management/04-UAT.md
    2. Confirm all 5 test entries show result: [pass] or result: [fail: ...] (no [pending])
    3. Confirm ## Summary block has correct counts summing to 5
    4. All 5 test results documented before proceeding to Task 2
  </how-to-verify>
  <resume-signal>Type "tests done" with a brief summary: how many passed, how many failed (and which). If any tests failed, describe the observed behavior so Task 2 can document it accurately.</resume-signal>
</task>

<task type="auto">
  <name>Task 2: Write 04-VERIFICATION.md with ENG-03 and WEB-03 sign-off</name>
  <files>.planning/phases/04-workspace-file-management/04-VERIFICATION.md</files>
  <action>
    Write the verification report to `.planning/phases/04-workspace-file-management/04-VERIFICATION.md`.

    CRITICAL: The file MUST go to the Phase 4 directory, NOT the Phase 6 directory.

    Read the UAT results from `.planning/phases/04-workspace-file-management/04-UAT.md` first,
    then write the VERIFICATION.md following the format established by the Phase 5 VERIFICATION.md
    at `.planning/phases/05-local-model-support-via-ollama/05-VERIFICATION.md`.

    The file must include:

    1. YAML frontmatter block:
       - `phase: 04-workspace-file-management`
       - `verified: <current ISO timestamp>`
       - `status: passed` (if all 5 tests pass) or `partial` (if any test fails)
       - `score: X/5 UAT tests passed`

    2. Header: "# Phase 4: Workspace & File Management — Verification Report" plus phase goal,
       verified date, status, and re-verification note (this is the initial verification).

    3. Observable Truths table — one row per UAT test:
       | # | Truth | Status | Evidence |
       - Truth 1: "Files uploaded via Chainlit UI appear in ./workspace"
       - Truth 2: "Agent lists ./workspace contents via list_workspace_files tool"
       - Truth 3: "Uploaded files accessible inside Docker at /workspace"
       - Truth 4: "/files command returns workspace listing with download links"
       - Truth 5: "Agent-created files auto-discovered and offered for download"
       - Status: VERIFIED or FAILED based on UAT result
       - Evidence: "UAT Test N: [pass]" or "UAT Test N: [fail: description]"

    4. Required Artifacts table — verify the key files exist and contain expected symbols:
       | Artifact | Expected | Status | Details |
       - `src/agent/tools/workspace.py` — list_workspace_files, get_workspace_snapshot, get_workspace_diff
       - `src/web_ui.py` — handle_file_uploads, send_file_diff, /files command handler
       - Docker bind-mount — ./workspace to /workspace inside container (from 04-01-SUMMARY.md)

    5. Requirements Coverage table:
       | Requirement | Source Plans | Description | Status | Evidence |
       - ENG-03 | 04-01, 04-02 | Support workspace file management for agent | SATISFIED or PARTIAL | UAT tests 1-5 evidence
       - WEB-03 | 04-02 | Provide a UI-based file manager for interacting with the agent's workspace | SATISFIED or PARTIAL | UAT tests 1, 4, 5 evidence (upload, /files, auto-discovery)

    6. Gaps Summary section:
       - If all tests pass: "No gaps found."
       - If any tests fail: List each failed test with observed behavior and impact on requirement

    Use the Phase 5 VERIFICATION.md as a structural template. Do NOT copy its content — derive
    all evidence from the actual Phase 4 UAT results recorded in 04-UAT.md.
  </action>
  <verify>
    <automated>python3 -c "
import pathlib, sys
p = pathlib.Path('.planning/phases/04-workspace-file-management/04-VERIFICATION.md')
if not p.exists():
    print('FAIL: 04-VERIFICATION.md does not exist')
    sys.exit(1)
content = p.read_text()
checks = ['ENG-03', 'WEB-03', 'UAT Test 1', 'UAT Test 5', 'phase: 04-workspace-file-management']
missing = [c for c in checks if c not in content]
if missing:
    print(f'FAIL: Missing required content: {missing}')
    sys.exit(1)
print('PASS: 04-VERIFICATION.md exists with required content')
"
    </automated>
  </verify>
  <done>04-VERIFICATION.md exists at .planning/phases/04-workspace-file-management/04-VERIFICATION.md with YAML frontmatter, all 5 observable truths, Requirements Coverage table formally signing off on ENG-03 and WEB-03 with UAT test number evidence.</done>
</task>

</tasks>

<verification>
After both tasks complete:
1. .planning/phases/04-workspace-file-management/04-UAT.md has no [pending] results; summary block counts are accurate
2. .planning/phases/04-workspace-file-management/04-VERIFICATION.md exists with correct frontmatter, Observable Truths table, and Requirements Coverage table
3. ENG-03 and WEB-03 are formally signed off with UAT test evidence
4. Run: `python3 -c "import pathlib; p=pathlib.Path('.planning/phases/04-workspace-file-management/04-VERIFICATION.md'); print(p.read_text()[:200])"`
   Expected: Shows YAML frontmatter with `phase: 04-workspace-file-management`
</verification>

<success_criteria>
- All 5 UAT tests attempted and results recorded (no test left as [pending])
- 04-VERIFICATION.md exists and references UAT test numbers for ENG-03 and WEB-03 evidence
- VERIFICATION.md status field reflects actual test outcome (passed or partial)
- Milestone v1.0 moves from 9/11 to 11/11 formally verified requirements
</success_criteria>

<output>
After completion, create `.planning/phases/06-phase4-workspace-verification/06-01-SUMMARY.md`
</output>
